{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa22363",
   "metadata": {},
   "source": [
    "### Creazione del Dizionario JSON del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167837c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f7389",
   "metadata": {},
   "source": [
    "#### Specifiche dei paragrafi\n",
    "\n",
    "- i paragrafi validi per l’analisi dovranno contenere un numero di token compreso tra 50 e 100 \n",
    "- i token potranno essere approssimati dividendo il testo sugli spazi, senza ricorrere a una tokenizzazione linguistica\n",
    "avanzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49f2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Testi progetto/Serao Matilde - 1856-1927/serao_gli_amanti_norm.txt', 'Testi progetto/Serao Matilde - 1856-1927/serao_piccole_anime_norm.txt', 'Testi progetto/Serao Matilde - 1856-1927/serao_l_infedele_norm.txt', 'Testi progetto/Serao Matilde - 1856-1927/serao_le_amanti_norm.txt', 'Testi progetto/Serao Matilde - 1856-1927/serao_la_conquista_di_roma_norm.txt', 'Testi progetto/Neera Zuccari Anna Maria - 1846 - 1918/neera_l_amuleto_norm.txt', 'Testi progetto/Neera Zuccari Anna Maria - 1846 - 1918/neera_le_idee_di_una_donna_norm.txt', 'Testi progetto/Neera Zuccari Anna Maria - 1846 - 1918/neera_la_vecchia_casa_norm.txt', 'Testi progetto/Neera Zuccari Anna Maria - 1846 - 1918/neera_rogo_d_amore_norm.txt', 'Testi progetto/Neera Zuccari Anna Maria - 1846 - 1918/neera_il_sogno_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_tempesta_e_bonaccia_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_cara_speranza_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_cartella_n_4_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_serate_d_inverno_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_senza_amore_norm.txt', 'Testi progetto/Colombi Marchesa, 1840-1920/colombi_i_ragazzi_d_una_volta_norm.txt']\n"
     ]
    }
   ],
   "source": [
    "# mi muovo nella cartella dove sono contenuti i miei file e ciclo sulle sotto cartelle e sui file per ottenerli tutti (solo quelli già normalizzati)\n",
    "\n",
    "lista_file = []\n",
    "for cartella, sottocartelle, files in os.walk(\"Testi progetto\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"_norm.txt\"):\n",
    "            file_path = cartella+\"/\"+file\n",
    "            lista_file.append(file_path)\n",
    "print(lista_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae449e82",
   "metadata": {},
   "source": [
    "Funzione che prende in input la lista dei token della frase e controlla la lunghezza: se è compresa tra 50 e 100, appende direttamente il paragrafo; se è maggiore di 100, spezza la frase al primo punto presente, controlla la lunghezza, verifica la validità, appende se necessario e poi richiama sé stessa sul resto del paragrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f14b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragrafi_scelti = []\n",
    "\n",
    "def elabora_lista_token(lista_token):\n",
    "\n",
    "    global paragrafi_scelti\n",
    "    # se il paragrafo è minore di 50 token, lo scarta\n",
    "    if len(lista_token)<50:\n",
    "       return\n",
    "    # se è compreso tra 50 e 100, lo appende\n",
    "    elif(len(lista_token)>=50 and len(lista_token)<=100):\n",
    "        paragrafi_scelti.append(\" \".join(lista_token))\n",
    "        return\n",
    "    # altrimenti, scorre il paragrafo al primo segno di punteggiatura disponibile\n",
    "    else:\n",
    "        contatore = 49\n",
    "        while not lista_token[contatore].endswith(\".\") and contatore < len(lista_token)-1:\n",
    "            contatore +=1\n",
    "        # se il paragrafo risultante è minore di 100, lo appende\n",
    "        if contatore <= 100:\n",
    "            paragrafi_scelti.append(\" \".join(lista_token[0:contatore+1]))\n",
    "        # rilancia sé stessa e riparte\n",
    "        elabora_lista_token(lista_token[contatore+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca9bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selezione_paragrafi(libro):\n",
    "\n",
    "    global paragrafi_scelti\n",
    "    paragrafi_scelti = []\n",
    "    # Spezzo il testo in paragrafi\n",
    "    lista_paragrafi = libro.split(\"\\n\\n\")\n",
    "    # Scorro i paragrafi nel testo. Per ciascuno, creo una lista di token splittando sugli spazi. \n",
    "    for paragrafo in lista_paragrafi:\n",
    "        lista_token_paragrafo = paragrafo.split(\" \")\n",
    "        # chiamo la funzione che spezza la frase quando necessario\n",
    "        elabora_lista_token(lista_token_paragrafo)\n",
    "    return paragrafi_scelti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e91101",
   "metadata": {},
   "source": [
    "#### Ciclo la lista di file, per ciascuno lancio la funzione di selezione paragrafi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cd0ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un dizionario che conterrà i paragrafi scelti di ogni autrice.\n",
    "# Assumo (visto che le specifiche non lo precisano) che non mi serva portarmi dietro il nome del libro dal quale viene ciascun capitolo.\n",
    "dizionario_autrici = {}\n",
    "for file in lista_file:\n",
    "\n",
    "    f = open(file)\n",
    "    libro = f.read()\n",
    "    # Ottengo la lista di paragrafi scelti del file\n",
    "    paragrafi = selezione_paragrafi(libro)\n",
    "\n",
    "    autrice = file.split(\"/\")[1]\n",
    "\n",
    "    # Scorro il dizionario delle autrici. \n",
    "    # Se l'autrice non è presente, creo una chiave a suo nome e inserisco la lista appena estratta come valore\n",
    "    if autrice not in dizionario_autrici:\n",
    "        dizionario_autrici[autrice] = {}\n",
    "        \n",
    "    # Ottengo il nome dell'autrice e il nome del libro (da usare come chiave)\n",
    "    nome_file = file.split(\"/\")[2]\n",
    "    nome_libro = nome_file.replace(\"_norm.txt\",\"\")\n",
    "    \n",
    "    dizionario_autrici[autrice][nome_libro] = paragrafi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b041c6",
   "metadata": {},
   "source": [
    "##### Salvo il dizionario creato in un file json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522f0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dizionario_paragrafi.json\", \"w\", encoding = 'utf8') as outfile:\n",
    "    json.dump(dizionario_autrici, outfile, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
